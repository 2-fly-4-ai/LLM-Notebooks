üê£ Please follow me for new updates https://twitter.com/camenduru <br />
üî• Please join our discord server https://discord.gg/k5BwmmvJJU

## üö¶ WIP üö¶

## ü¶í Colab
| colab | Info - Model Page
| --- | --- |
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/vicuna-13b-GPTQ-4bit-128g.ipynb) | vicuna-13b-GPTQ-4bit-128g <br /> https://vicuna.lmsys.org (recommended)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/gpt4-x-alpaca-13b-native-4bit-128g.ipynb) | gpt4-x-alpaca-13b-native-4bit-128g <br /> https://crfm.stanford.edu/2023/03/13/alpaca.html <br /> This model doesn't work with Free T4 GPU üò≠
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/alpaca-7b-native-4bit.ipynb) | alpaca-7b-native-4bit <br /> https://github.com/tatsu-lab/stanford_alpaca
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-13b-3bit-gr128.ipynb) | llama-13b-3bit-gr128 <br /> https://github.com/facebookresearch/llama This model doesn't work with Free T4 GPU üò≠
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-13b-4bit-gr128.ipynb) | llama-13b-4bit-gr128 <br /> https://github.com/facebookresearch/llama This model doesn't work with Free T4 GPU üò≠


## Text Generation Web UI
[https://github.com/oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) (Thanks to @oobabooga ‚ù§)

## Models License
| Model | License
| --- | --- |
vicuna-13b-GPTQ-4bit-128g | From https://vicuna.lmsys.org: The online demo is a research preview intended for non-commercial use only, subject to the model [License](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) of LLaMA, Terms of Use of the data generated by OpenAI, and Privacy Practices of ShareGPT. Please contact us If you find any potential violation. The code is released under the Apache License 2.0.
gpt4-x-alpaca-13b-native-4bit-128g | https://huggingface.co/chavinlo/alpaca-native -> https://huggingface.co/chavinlo/alpaca-13b -> https://huggingface.co/chavinlo/gpt4-x-alpaca
alpaca-7b-native-4bit | https://github.com/tatsu-lab/stanford_alpaca/blob/main/LICENSE

## Special Thanks
Thanks to facebookresearch ‚ù§ for https://github.com/facebookresearch/llama <br />
Thanks to tatsu-lab ‚ù§ for https://github.com/tatsu-lab/stanford_alpaca <br />
Thanks to lmsys ‚ù§ for https://huggingface.co/lmsys/vicuna-13b-delta-v0 <br />
Thanks to chavinlo ‚ù§ for https://huggingface.co/chavinlo/gpt4-x-alpaca <br />
Thanks to qwopqwop200 ‚ù§ for https://github.com/qwopqwop200/GPTQ-for-LLaMa <br />
Thanks to anon8231489123 ‚ù§ for https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g (GPTQ 4bit quantization of: https://huggingface.co/lmsys/vicuna-13b-delta-v0) <br />
Thanks to anon8231489123 ‚ù§ for https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g (GPTQ 4bit quantization of: https://huggingface.co/chavinlo/gpt4-x-alpaca) <br />
Thanks to huggingface ‚ù§ for https://github.com/huggingface/transformers <br />
Thanks to gradio-app ‚ù§ for https://github.com/gradio-app/gradio <br />
Thanks to ozcur ‚ù§ for https://huggingface.co/ozcur/alpaca-native-4bit (GPTQ 4bit quantization of: https://huggingface.co/chavinlo/alpaca-native)  <br />
Thanks to wcde ‚ù§ for https://huggingface.co/wcde/llama-13b-4bit-gr128 (GPTQ 4bit quantization of: https://huggingface.co/decapoda-research/llama-13b-hf)  <br />
